{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cambridgespark.com/content/tutorials/deep-learning-for-complete-beginners-recognising-handwritten-digits/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist # subroutines for fetching the MNIST dataset\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Dense # the two types of neural network layer we will be using\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128 # in each iteration, we consider 128 training examples at once\n",
    "num_epochs = 20 # we iterate twenty times over the entire training set\n",
    "hidden_size = 512 # there will be 512 neurons in both hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to load and preprocess the MNIST data set. Keras makes this extremely simple, with a fixed interface for fetching and extracting the data from the remote server, directly into NumPy arrays.\n",
    "\n",
    "To preprocess the input data, we will first flatten the images into 1D (as we will consider each pixel as a separate input feature), and we will then force the pixel intensity values to be in the [0,1][0,1] range by dividing them by 255255. This is a very simple way to \"normalise\" the data, and I will be discussing other ways in future tutorials in this series.\n",
    "\n",
    "A good approach to a classification problem is to use probabilistic classification, i.e. to have a single output neuron for each class, outputting a value which corresponds to the probability of the input being of that particular class. This implies a need to transform the training output data into a \"one-hot\" encoding: for example, if the desired output class is 33, and there are five classes overall (labelled 00 to 44), then an appropriate one-hot encoding is: [0 0 0 1 0][0 0 0 1 0]. Keras, once again, provides us with an out-of-the-box functionality for doing just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # fetch MNIST data   ##  https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = 60000 # there are 60000 training examples in MNIST\n",
    "num_test = 10000 # there are 10000 test examples in MNIST\n",
    "\n",
    "height, width, depth = 28, 28, 1 # MNIST images are 28x28 and greyscale\n",
    "num_classes = 10 # there are 10 classes (1 per digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.reshape(num_train, height * width) # Flatten data to 1D\n",
    "X_test = X_test.reshape(num_test, height * width) # Flatten data to 1D\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 # Normalise data to [0, 1] range\n",
    "X_test /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An excellent feature of Keras, that sets it apart from frameworks such as TensorFlow, is automatic inference of shapes; we only need to specify the shape of the input layer, and afterwards Keras will take care of initialising the weight variables with proper shapes. Once all the layers have been defined, we simply need to identify the input(s) and the output(s) in order to define our model, as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(height * width,)) # Our input is a 1D vector of size 784\n",
    "hidden_1 = Dense(hidden_size, activation='relu')(inp) # First hidden ReLU layer\n",
    "hidden_2 = Dense(hidden_size, activation='relu')(hidden_1) # Second hidden ReLU layer\n",
    "out = Dense(num_classes, activation='softmax')(hidden_2) # Output softmax layer\n",
    "\n",
    "model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we call the training algorithm with the determined batch size and epoch count. It is good practice to set aside a fraction of the training data to be used just for verification that our algorithm is (still) properly generalising (this is commonly referred to as the validation set); here we will hold out 10%10% of the data for this purpose.\n",
    "\n",
    "An excellent out-of-the-box feature of Keras is verbosity; it's able to provide detailed real-time pretty-printing of the training algorithm's progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.2297 - acc: 0.9332 - val_loss: 0.0992 - val_acc: 0.9697\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0838 - acc: 0.9736 - val_loss: 0.0726 - val_acc: 0.9787\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 10s - loss: 0.0533 - acc: 0.9830 - val_loss: 0.0661 - val_acc: 0.9803\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0357 - acc: 0.9887 - val_loss: 0.0731 - val_acc: 0.9792\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 9s - loss: 0.0284 - acc: 0.9907 - val_loss: 0.0939 - val_acc: 0.9750\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 10s - loss: 0.0232 - acc: 0.9922 - val_loss: 0.0715 - val_acc: 0.9812\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 10s - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0923 - val_acc: 0.9767\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0189 - acc: 0.9936 - val_loss: 0.0793 - val_acc: 0.9817\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0148 - acc: 0.9949 - val_loss: 0.1058 - val_acc: 0.9763\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 10s - loss: 0.0141 - acc: 0.9952 - val_loss: 0.0857 - val_acc: 0.9810\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0136 - acc: 0.9956 - val_loss: 0.0793 - val_acc: 0.9840\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 10s - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0785 - val_acc: 0.9833\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 10s - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0929 - val_acc: 0.9800\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0946 - val_acc: 0.9805\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0805 - val_acc: 0.9840\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0078 - acc: 0.9976 - val_loss: 0.0916 - val_acc: 0.9817\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0894 - val_acc: 0.9825\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0844 - val_acc: 0.9843\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0848 - val_acc: 0.9838\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 11s - loss: 0.0050 - acc: 0.9984 - val_loss: 0.1011 - val_acc: 0.9810\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'do_validation': True,\n",
       " 'epochs': 20,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc'],\n",
       " 'samples': 54000,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.93320370366838246,\n",
       "  0.97362962966495092,\n",
       "  0.98298148148148146,\n",
       "  0.9887407407407407,\n",
       "  0.9907407407407407,\n",
       "  0.99220370365072175,\n",
       "  0.99429629624331439,\n",
       "  0.99361111111111111,\n",
       "  0.99487037031738845,\n",
       "  0.9952037037037037,\n",
       "  0.99555555555555553,\n",
       "  0.99742592592592594,\n",
       "  0.99657407407407406,\n",
       "  0.99592592592592588,\n",
       "  0.99727777777777782,\n",
       "  0.99759259259259259,\n",
       "  0.99698148148148147,\n",
       "  0.99659259259259259,\n",
       "  0.99837037037037035,\n",
       "  0.99842592592592594],\n",
       " 'loss': [0.22969011269233844,\n",
       "  0.083814107696215306,\n",
       "  0.053340408792374311,\n",
       "  0.035700464509565523,\n",
       "  0.028415165638206182,\n",
       "  0.023194558339262449,\n",
       "  0.01734717335689951,\n",
       "  0.018903483948842795,\n",
       "  0.01483916344748879,\n",
       "  0.014136188557164536,\n",
       "  0.01362741678175344,\n",
       "  0.0079974225247192582,\n",
       "  0.011173214733333292,\n",
       "  0.012002236604112787,\n",
       "  0.0078907485657578533,\n",
       "  0.0078138771694610584,\n",
       "  0.0092543915426401696,\n",
       "  0.0099837583741086908,\n",
       "  0.0045775625572401892,\n",
       "  0.0050460583646576938],\n",
       " 'val_acc': [0.96966666634877519,\n",
       "  0.97866666634877519,\n",
       "  0.9803333330154419,\n",
       "  0.9791666661898295,\n",
       "  0.9749999996821086,\n",
       "  0.98116666618982951,\n",
       "  0.97666666682561243,\n",
       "  0.98166666618982956,\n",
       "  0.97633333285649615,\n",
       "  0.98099999952316286,\n",
       "  0.98400000015894573,\n",
       "  0.98333333285649616,\n",
       "  0.97999999952316286,\n",
       "  0.9804999995231628,\n",
       "  0.98399999952316286,\n",
       "  0.98166666618982956,\n",
       "  0.9824999995231628,\n",
       "  0.98433333285649616,\n",
       "  0.98383333285649621,\n",
       "  0.98099999952316286],\n",
       " 'val_loss': [0.099233867168426512,\n",
       "  0.072615306834379834,\n",
       "  0.066057203774650894,\n",
       "  0.073120672941207887,\n",
       "  0.093869212120771414,\n",
       "  0.071450149934738874,\n",
       "  0.092258868116885426,\n",
       "  0.079325872649438675,\n",
       "  0.10579219937231392,\n",
       "  0.085666519521968437,\n",
       "  0.079262047071970307,\n",
       "  0.078500965790512661,\n",
       "  0.092859128381736808,\n",
       "  0.094550392109590278,\n",
       "  0.080542152005868659,\n",
       "  0.091642812907656968,\n",
       "  0.089429146493571657,\n",
       "  0.084400692559351828,\n",
       "  0.084784308347671561,\n",
       "  0.10106238250834092]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9664/10000 [===========================>..] - ETA: 0sscore:: [0.08414624073373507, 0.98160000000000003]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!\n",
    "print('score::',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.0841462407337\n",
      "Test accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets predict one single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x270d5bfe860>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADaVJREFUeJzt3X+MHPV5x/HPJ/b5iA9oMQTXNQ4ODUF1aHCki0kErRwR\nUiBBJkpCsVTLlShGLY2gitoiV1EttUopCkFuk0ZyghuDCNAGEFbipoJTWwuVOj6QsQHTmlCnsWt8\ngGltApxt/PSPG0cXuP3esb9mz8/7JZ1ud56ZnUfj+3hm97u7X0eEAOTzrrobAFAPwg8kRfiBpAg/\nkBThB5Ii/EBShB9IivADSRF+IKmZ3dzZLPfHSRro5i6BVN7QT3U4Rj2VdVsKv+3LJK2VNEPStyLi\nltL6J2lAF/qSVnYJoGBLDE153aYv+23PkPR1SZdLWiRpue1FzT4egO5q5Tn/EknPRcTzEXFY0r2S\nlrWnLQCd1kr450v6ybj7e6plP8f2KtvDtoePaLSF3QFop46/2h8R6yJiMCIG+9Tf6d0BmKJWwr9X\n0oJx98+qlgGYBloJ/1ZJ59p+n+1Zkq6RtLE9bQHotKaH+iLiqO0/kPRPGhvqWx8RT7etMwAd1dI4\nf0RskrSpTb0A6CLe3gskRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8\nQFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii\n/EBSLc3Sa3u3pEOS3pR0NCIG29EUgM5rKfyVj0fES214HABdxGU/kFSr4Q9Jj9h+3PaqdjQEoDta\nvey/OCL22j5T0sO2n42IzeNXqP5TWCVJJ2l2i7sD0C4tnfkjYm/1e0TSg5KWTLDOuogYjIjBPvW3\nsjsAbdR0+G0P2D7l+G1Jn5T0VLsaA9BZrVz2z5X0oO3jj/OdiPhBW7oC0HFNhz8inpd0QRt7AdBF\nDPUBSRF+ICnCDyRF+IGkCD+QFOEHkmrHp/pSePm6jzWsvXfFc8Vtnx2ZW6wfHu0r1uffU67P3vNq\nw9qxbc8Ut0VenPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnG+afoj//oOw1rnx14pbzxr7S486Xl\n8u6jrzWsrX3x4y3ufPr64cjZDWsDt/1CcduZQ4+3u52ew5kfSIrwA0kRfiApwg8kRfiBpAg/kBTh\nB5JyRHRtZ6d6TlzoS7q2v3b66ecubFh76UPl/0NP21k+xq/8qov1WR/632L91vMfaFi79N2vF7f9\n/msnF+ufmt34uwJa9XocLta3jA4U60tPOtL0vt///euL9Q+s2tr0Y9dpSwzpYBwo/0FVOPMDSRF+\nICnCDyRF+IGkCD+QFOEHkiL8QFKTfp7f9npJn5Y0EhHnV8vmSLpP0kJJuyVdHRGTfKh9ehv47pZC\nrbXHPrW1zfU3v7S0Ye0vLlpY3ve/luccuHXp+5voaGpmvn6sWB/Yvq9YP33z/cX6r81qPN/B7N3l\nuRAymMqZ/9uSLnvLspslDUXEuZKGqvsAppFJwx8RmyUdeMviZZI2VLc3SLqqzX0B6LBmn/PPjYjj\n12QvSCrPRwWg57T8gl+MfTig4ZvXba+yPWx7+IhGW90dgDZpNvz7bc+TpOr3SKMVI2JdRAxGxGCf\n+pvcHYB2azb8GyWtrG6vlPRQe9oB0C2Tht/2PZIek3Se7T22r5V0i6RLbe+S9InqPoBpZNJx/ohY\n3qA0PT+YfwI6+sL+hrWB+xvXJOnNSR574LsvN9FRe+z/3Y8V6x+cVf7z/cqB8xrWFv7d88Vtjxar\nJwbe4QckRfiBpAg/kBThB5Ii/EBShB9Iiim6UZuZZy8o1r+2+mvFep9nFOv/sPYTDWun73usuG0G\nnPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnG+VGbZ/9wfrH+kf7yTNNPHy5PPz7nmdfecU+ZcOYH\nkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQY50dHjX7qIw1rT3zu9km2Ls/w9Hs33lisv/vffjjJ4+fG\nmR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkpp0nN/2ekmfljQSEedXy9ZIuk7Si9VqqyNiU6eaxPT1\n35c3Pr+c7PI4/vL/urRYn/2DJ4v1KFYxlTP/tyVdNsHy2yNicfVD8IFpZtLwR8RmSQe60AuALmrl\nOf8XbG+3vd72aW3rCEBXNBv+b0g6R9JiSfsk3dZoRdurbA/bHj6i0SZ3B6Ddmgp/ROyPiDcj4pik\nb0paUlh3XUQMRsRg3yQf1ADQPU2F3/a8cXc/I+mp9rQDoFumMtR3j6Slks6wvUfSn0laanuxxkZT\ndku6voM9AuiAScMfEcsnWHxHB3rBNPSuU04p1lf8+qMNawePvVHcduTL5xTr/aNbi3WU8Q4/ICnC\nDyRF+IGkCD+QFOEHkiL8QFJ8dTdasmvNB4v1753xtw1ry3Z9trht/yaG8jqJMz+QFOEHkiL8QFKE\nH0iK8ANJEX4gKcIPJMU4P4r+77c/Wqxv/62/LtZ/dPRIw9qrf3VWcdt+7SvW0RrO/EBShB9IivAD\nSRF+ICnCDyRF+IGkCD+QFOP8yc2c/8vF+k1fuq9Y73f5T+iaJ1c0rL3nH/m8fp048wNJEX4gKcIP\nJEX4gaQIP5AU4QeSIvxAUpOO89teIOlOSXMlhaR1EbHW9hxJ90laKGm3pKsj4pXOtYpmeGb5n/iC\n7+0p1j9/8svF+t2HzizW536p8fnlWHFLdNpUzvxHJX0xIhZJ+qikG2wvknSzpKGIOFfSUHUfwDQx\nafgjYl9EPFHdPiRpp6T5kpZJ2lCttkHSVZ1qEkD7vaPn/LYXSvqwpC2S5kbE8e9ZekFjTwsATBNT\nDr/tkyXdL+mmiDg4vhYRobHXAybabpXtYdvDRzTaUrMA2mdK4bfdp7Hg3x0RD1SL99ueV9XnSRqZ\naNuIWBcRgxEx2Kf+dvQMoA0mDb9tS7pD0s6I+Oq40kZJK6vbKyU91P72AHTKVD7Se5GkFZJ22N5W\nLVst6RZJf2/7Wkk/lnR1Z1pESy44r1j+8zPvaunhv/7lzxfrv/jkYy09Pjpn0vBHxKOS3KB8SXvb\nAdAtvMMPSIrwA0kRfiApwg8kRfiBpAg/kBRf3X0CmLHoAw1rq+5t7b1Xi9bfUKwvvOvfW3p81Icz\nP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTj/CeDZ3z+tYe3K2Qcb1qbirH85XF4hJvz2NkwDnPmB\npAg/kBThB5Ii/EBShB9IivADSRF+ICnG+aeBN65cUqwPXXlboTq7vc3ghMGZH0iK8ANJEX4gKcIP\nJEX4gaQIP5AU4QeSmnSc3/YCSXdKmispJK2LiLW210i6TtKL1aqrI2JTpxrN7H8umlGsv3dm82P5\ndx86s1jvO1j+PD+f5p++pvImn6OSvhgRT9g+RdLjth+uardHxFc61x6ATpk0/BGxT9K+6vYh2zsl\nze90YwA66x0957e9UNKHJW2pFn3B9nbb621P+F1StlfZHrY9fESjLTULoH2mHH7bJ0u6X9JNEXFQ\n0jcknSNpscauDCZ8g3lErIuIwYgY7FN/G1oG0A5TCr/tPo0F/+6IeECSImJ/RLwZEcckfVNS+dMn\nAHrKpOG3bUl3SNoZEV8dt3zeuNU+I+mp9rcHoFOm8mr/RZJWSNphe1u1bLWk5bYXa2y0Z7ek6zvS\nIVryly8vKtYf+82FxXrs29HGbtBLpvJq/6OSPEGJMX1gGuMdfkBShB9IivADSRF+ICnCDyRF+IGk\nHF2cYvlUz4kLfUnX9gdksyWGdDAOTDQ0/zac+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqa6O89t+\nUdKPxy06Q9JLXWvgnenV3nq1L4nemtXO3s6OiPdMZcWuhv9tO7eHI2KwtgYKerW3Xu1Lordm1dUb\nl/1AUoQfSKru8K+ref8lvdpbr/Yl0Vuzaumt1uf8AOpT95kfQE1qCb/ty2z/h+3nbN9cRw+N2N5t\ne4ftbbaHa+5lve0R20+NWzbH9sO2d1W/J5wmrabe1tjeWx27bbavqKm3Bbb/2fYztp+2fWO1vNZj\nV+irluPW9ct+2zMk/aekSyXtkbRV0vKIeKarjTRge7ekwYiofUzY9m9IelXSnRFxfrXsVkkHIuKW\n6j/O0yLiT3qktzWSXq175uZqQpl542eWlnSVpN9Rjceu0NfVquG41XHmXyLpuYh4PiIOS7pX0rIa\n+uh5EbFZ0oG3LF4maUN1e4PG/ni6rkFvPSEi9kXEE9XtQ5KOzyxd67Er9FWLOsI/X9JPxt3fo96a\n8jskPWL7cdur6m5mAnOradMl6QVJc+tsZgKTztzcTW+ZWbpnjl0zM163Gy/4vd3FEbFY0uWSbqgu\nb3tSjD1n66XhminN3NwtE8ws/TN1HrtmZ7xutzrCv1fSgnH3z6qW9YSI2Fv9HpH0oHpv9uH9xydJ\nrX6P1NzPz/TSzM0TzSytHjh2vTTjdR3h3yrpXNvvsz1L0jWSNtbQx9vYHqheiJHtAUmfVO/NPrxR\n0srq9kpJD9XYy8/plZmbG80srZqPXc/NeB0RXf+RdIXGXvH/kaQ/raOHBn2dI+nJ6ufpunuTdI/G\nLgOPaOy1kWslnS5pSNIuSY9ImtNDvd0laYek7RoL2ryaertYY5f02yVtq36uqPvYFfqq5bjxDj8g\nKV7wA5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+Q1P8DC8wZVCobNIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x270c1783f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "X_test_0 = X_test[0,:].reshape(1,height * width)\n",
    "Y_test_0 = Y_test[0,:]\n",
    "print(Y_test_0)\n",
    "plt.imshow(X_test_0.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of testing sample: 7\n",
      "\n",
      "Output of the softmax layer: [  4.46629025e-17   3.17146461e-12   8.96795767e-13   2.02302577e-10\n",
      "   2.23746927e-19   1.15318482e-17   3.32788719e-18   1.00000000e+00\n",
      "   8.63590125e-18   4.20364004e-12]\n",
      "\n",
      "Neural Network prediction: 7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred = model.predict(X_test_0)\n",
    "print('Label of testing sample:', np.argmax(Y_test_0))\n",
    "print('\\nOutput of the softmax layer:',pred[0])\n",
    "print('\\nNeural Network prediction:', np.argmax(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
